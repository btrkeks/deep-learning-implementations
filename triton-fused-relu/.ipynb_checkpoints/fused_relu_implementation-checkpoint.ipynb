{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "\n",
    "Write a custom fused ReLU class for 2D tensors, that implements **vector addition and ReLU**, with the **forward** pass. Then write a fused ReLU Triton kernel for 2D tensors that performs the **vector addition and ReLU** with the **forward** pass and computes its matching **backward** pass. Verify that both implementations produce the same outputs and gradients on random inputs and write a benchmark test with 'triton.testing' to showcase the efficiency of Triton in comparison to Torch. And you should look into **PyTorch's JIT** to make your pytorch implementation more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading scheme\n",
    "Total: 5 points\n",
    "1. **Implementation of the forward pass for the fused ReLU with PyTorch** (0.5 points)\n",
    "2. **Implementation of the forward & backward pass for the fused ReLU with Triton** (4 points)\n",
    "3. **Verify outputs & benchmark test** (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7_u2od9bODIg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import triton.language as tl\n",
    "import triton\n",
    "import triton.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0 active drivers ([]). There should only be one.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m DEVICE = \u001b[43mtriton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_active_torch_device\u001b[49m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/driver.py:23\u001b[39m, in \u001b[36mLazyProxy.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._obj, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/driver.py:20\u001b[39m, in \u001b[36mLazyProxy._initialize_obj\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_initialize_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         \u001b[38;5;28mself\u001b[39m._obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/driver.py:8\u001b[39m, in \u001b[36m_create_driver\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m actives = [x.driver \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m backends.values() \u001b[38;5;28;01mif\u001b[39;00m x.driver.is_active()]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actives) != \u001b[32m1\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(actives)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m active drivers (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactives\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). There should only be one.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m actives[\u001b[32m0\u001b[39m]()\n",
      "\u001b[31mRuntimeError\u001b[39m: 0 active drivers ([]). There should only be one."
     ]
    }
   ],
   "source": [
    "DEVICE = triton.runtime.driver.active.get_active_torch_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implementation of the forward pass for the fused ReLU with PyTorch (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchAddReLU(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        assert y.dim() == 2 and y.dim() == 2\n",
    "\n",
    "        added = x + y\n",
    "        mask = added > 0\n",
    "        ctx.save_for_backward(mask)\n",
    "        return added * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementation of the forward & backward pass for the fused ReLU with Triton (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def add_relu_kernel(x_ptr,\n",
    "               y_ptr,\n",
    "               output_ptr,\n",
    "               n_elements,\n",
    "               BLOCK_SIZE: tl.constexpr,\n",
    "               ):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < n_elements\n",
    "    \n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    y = tl.load(y_ptr + offsets, mask=mask)\n",
    "    \n",
    "    summed = x + y\n",
    "    relued = tl.where(summed > 0, summed, 0)\n",
    "    \n",
    "    tl.store(output_ptr + offsets, output, mask=mask)\n",
    "\n",
    "def add_relu(x: torch.Tensor, y: torch.Tensor, BLOCK_SIZE=1024):\n",
    "    output = torch.empty_like(x)\n",
    "    n_elements = output.numel()\n",
    "\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
    "    add_relu_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Verify outputs & benchmark test (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 2.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(5).unsqueeze(0)\n",
    "y = - 2 * torch.ones(5).unsqueeze(0)\n",
    "F.relu(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., 0., 1., 2.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TorchAddReLU.apply(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0 active drivers ([]). There should only be one.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43madd_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36madd_relu\u001b[39m\u001b[34m(x, y, BLOCK_SIZE)\u001b[39m\n\u001b[32m     23\u001b[39m n_elements = output.numel()\n\u001b[32m     25\u001b[39m grid = \u001b[38;5;28;01mlambda\u001b[39;00m meta: (triton.cdiv(n_elements, meta[\u001b[33m'\u001b[39m\u001b[33mBLOCK_SIZE\u001b[39m\u001b[33m'\u001b[39m]), )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43madd_relu_kernel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_elements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBLOCK_SIZE\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/jit.py:330\u001b[39m, in \u001b[36mKernelInterface.__getitem__.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, grid) -> T:\n\u001b[32m    325\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[33;03m    A JIT function is launched with: fn[grid](*args, **kwargs).\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[33;03m    Hence JITFunction.__getitem__ returns a callable proxy that\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[33;03m    memorizes the grid.\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/jit.py:568\u001b[39m, in \u001b[36mJITFunction.run\u001b[39m\u001b[34m(self, grid, warmup, *args, **kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# parse options\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompiler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_backend\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m device = \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_current_device\u001b[49m()\n\u001b[32m    569\u001b[39m stream = driver.active.get_current_stream(device)\n\u001b[32m    570\u001b[39m target = driver.active.get_current_target()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/driver.py:23\u001b[39m, in \u001b[36mLazyProxy.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._obj, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/driver.py:20\u001b[39m, in \u001b[36mLazyProxy._initialize_obj\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_initialize_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         \u001b[38;5;28mself\u001b[39m._obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/triton/runtime/driver.py:8\u001b[39m, in \u001b[36m_create_driver\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m actives = [x.driver \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m backends.values() \u001b[38;5;28;01mif\u001b[39;00m x.driver.is_active()]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actives) != \u001b[32m1\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(actives)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m active drivers (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactives\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). There should only be one.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m actives[\u001b[32m0\u001b[39m]()\n",
      "\u001b[31mRuntimeError\u001b[39m: 0 active drivers ([]). There should only be one."
     ]
    }
   ],
   "source": [
    "add_relu(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
